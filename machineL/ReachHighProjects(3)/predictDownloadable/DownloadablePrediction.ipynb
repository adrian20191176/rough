{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import seaborn as sns\n",
    "# from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "# import plotly.plotly as py\n",
    "# import plotly.graph_objs as go\n",
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn import preprocessing\n",
    "# from sklearn.metrics import accuracy_score\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "# %matplotlib inline\n",
    "# init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3146: DtypeWarning: Columns (4,5,6) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>appId</th>\n",
       "      <th>Score</th>\n",
       "      <th>Text</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>com.fitbit.FitbitMobile</td>\n",
       "      <td>5</td>\n",
       "      <td>Awesome</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>com.fitbit.FitbitMobile</td>\n",
       "      <td>5</td>\n",
       "      <td>Fantastic app for tracking exercise workouts, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>com.fitbit.FitbitMobile</td>\n",
       "      <td>3</td>\n",
       "      <td>Won't stay connected to my phone</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>com.fitbit.FitbitMobile</td>\n",
       "      <td>5</td>\n",
       "      <td>Great help for staying fit!</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>com.fitbit.FitbitMobile</td>\n",
       "      <td>5</td>\n",
       "      <td>Fantastic for what I need love it</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     appId  Score  \\\n",
       "0  com.fitbit.FitbitMobile      5   \n",
       "1  com.fitbit.FitbitMobile      5   \n",
       "2  com.fitbit.FitbitMobile      3   \n",
       "3  com.fitbit.FitbitMobile      5   \n",
       "4  com.fitbit.FitbitMobile      5   \n",
       "\n",
       "                                                Text Unnamed: 3 Unnamed: 4  \\\n",
       "0                                            Awesome        NaN        NaN   \n",
       "1  Fantastic app for tracking exercise workouts, ...        NaN        NaN   \n",
       "2                   Won't stay connected to my phone        NaN        NaN   \n",
       "3                        Great help for staying fit!        NaN        NaN   \n",
       "4                  Fantastic for what I need love it        NaN        NaN   \n",
       "\n",
       "  Unnamed: 5 Unnamed: 6  \n",
       "0        NaN        NaN  \n",
       "1        NaN        NaN  \n",
       "2        NaN        NaN  \n",
       "3        NaN        NaN  \n",
       "4        NaN        NaN  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "playstore_reviews = pd.read_csv(\"reviews.csv\")\n",
    "playstore_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>appId</th>\n",
       "      <th>Text</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>com.fitbit.FitbitMobile</td>\n",
       "      <td>Awesome</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>com.fitbit.FitbitMobile</td>\n",
       "      <td>Fantastic app for tracking exercise workouts, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>com.fitbit.FitbitMobile</td>\n",
       "      <td>Won't stay connected to my phone</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>com.fitbit.FitbitMobile</td>\n",
       "      <td>Great help for staying fit!</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>com.fitbit.FitbitMobile</td>\n",
       "      <td>Fantastic for what I need love it</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     appId                                               Text  \\\n",
       "0  com.fitbit.FitbitMobile                                            Awesome   \n",
       "1  com.fitbit.FitbitMobile  Fantastic app for tracking exercise workouts, ...   \n",
       "2  com.fitbit.FitbitMobile                   Won't stay connected to my phone   \n",
       "3  com.fitbit.FitbitMobile                        Great help for staying fit!   \n",
       "4  com.fitbit.FitbitMobile                  Fantastic for what I need love it   \n",
       "\n",
       "  Unnamed: 3 Unnamed: 4 Unnamed: 5 Unnamed: 6  \n",
       "0        NaN        NaN        NaN        NaN  \n",
       "1        NaN        NaN        NaN        NaN  \n",
       "2        NaN        NaN        NaN        NaN  \n",
       "3        NaN        NaN        NaN        NaN  \n",
       "4        NaN        NaN        NaN        NaN  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "playstore_reviews.drop('Score',axis=1,inplace=True)\n",
    "playstore_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import json\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflowjs as tfjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "INDEX_FROM = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_index(reverse=False):\n",
    "  \"\"\"Get word index.\n",
    "  Args:\n",
    "    reverse: Reverse the index, so that the returned index is from index values\n",
    "      to words.\n",
    "  Returns:\n",
    "    The word index as a `dict`.\n",
    "  \"\"\"\n",
    "  word_index = tf.keras.datasets.imdb.get_word_index()\n",
    "  if reverse:\n",
    "    word_index = dict((word_index[key], key) for key in word_index)\n",
    "  return word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indices_to_words(reverse_index, indices):\n",
    "  \"\"\"Convert an iterable of word indices into words.\n",
    "  Args:\n",
    "    reverse_index: An `dict` mapping word index (as `int`) to word (as `str`).\n",
    "    indices: An iterable of word indices.\n",
    "  Returns:\n",
    "    Mapped words as a `list` of `str`s.\n",
    "  \"\"\"\n",
    "  return [reverse_index[i - INDEX_FROM] if i >= INDEX_FROM else 'OOV'\n",
    "          for i in indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_imdb_data(vocabulary_size, max_len):\n",
    "  \"\"\"Get IMDB data for training and validation.\n",
    "  Args:\n",
    "    vocabulary_size: Size of the vocabulary, as an `int`.\n",
    "    max_len: Cut text after this number of words.\n",
    "  Returns:\n",
    "    x_train: An int array of shape `(num_examples, max_len)`: index-encoded\n",
    "      sentences.\n",
    "    y_train: An int array of shape `(num_examples,)`: labels for the sentences.\n",
    "    x_test: Same as `x_train`, but for test.\n",
    "    y_test: Same as `y_train`, but for test.\n",
    "  \"\"\"\n",
    "  print(\"Getting IMDB data with vocabulary_size %d\" % vocabulary_size)\n",
    "  (x_train, y_train), (x_test, y_test) = tf.keras.datasets.imdb.load_data(\n",
    "      num_words=vocabulary_size)\n",
    "  x_train = tf.keras.preprocessing.sequence.pad_sequences(x_train, maxlen=max_len)\n",
    "  x_test = tf.keras.preprocessing.sequence.pad_sequences(x_test, maxlen=max_len)\n",
    "  return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model_type,\n",
    "                vocabulary_size,\n",
    "                embedding_size,\n",
    "                x_train,\n",
    "                y_train,\n",
    "                x_test,\n",
    "                y_test,\n",
    "                epochs,\n",
    "                batch_size):\n",
    "  \"\"\"Train a model for IMDB sentiment classification.\n",
    "  Args:\n",
    "    model_type: Type of the model to train, as a `str`.\n",
    "    vocabulary_size: Vocabulary size.\n",
    "    embedding_size: Embedding dimensions.\n",
    "    x_train: An int array of shape `(num_examples, max_len)`: index-encoded\n",
    "      sentences.\n",
    "    y_train: An int array of shape `(num_examples,)`: labels for the sentences.\n",
    "    x_test: Same as `x_train`, but for test.\n",
    "    y_test: Same as `y_train`, but for test.\n",
    "    epochs: Number of epochs to train the model for.\n",
    "    batch_size: Batch size to use during trainng.\n",
    "  Returns:\n",
    "    The trained model instance.\n",
    "  Raises:\n",
    "    ValueError: on invalid model type.\n",
    "  \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vocabulary_size' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-70-4d172acff194>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSequential\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEmbedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvocabulary_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0membedding_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mmodel_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'bidirectional_lstm'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;31m# TODO(cais): Uncomment the following once bug b/74429960 is fixed.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;31m# model.add(tf.keras.layers.Embedding(\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'vocabulary_size' is not defined"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Embedding(vocabulary_size, embedding_size))\n",
    "if model_type == 'bidirectional_lstm':\n",
    "    # TODO(cais): Uncomment the following once bug b/74429960 is fixed.\n",
    "    # model.add(tf.keras.layers.Embedding(\n",
    "    #     vocabulary_size, 128, input_length=maxlen))\n",
    "    # model.add(tf.keras.layers.Bidirectional(\n",
    "    #     tf.keras.layers.LSTM(64))\n",
    "    # model.add(tf.keras.layers.Dropout(0.5))\n",
    "    raise NotImplementedError()\n",
    "elif model_type == 'cnn':\n",
    "    model.add(tf.keras.layers.Dropout(0.2))\n",
    "    model.add(tf.keras.layers.Conv1D(250,\n",
    "                                  3,\n",
    "                                  padding='valid',\n",
    "                                  activation='relu',\n",
    "                                  strides=1))\n",
    "    model.add(tf.keras.layers.GlobalMaxPooling1D())\n",
    "    model.add(tf.keras.layers.Dense(250, activation='relu'))\n",
    "elif model_type == 'lstm':\n",
    "    model.add(tf.keras.layers.LSTM(128))\n",
    "else:\n",
    "    raise ValueError(\"Invalid model type: '%s'\" % model_type)\n",
    "    model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile('adam', 'binary_crossentropy', metrics=['accuracy'])\n",
    "    model.fit(x_train, y_train,\n",
    "            batch_size=batch_size,\n",
    "            epochs=epochs,\n",
    "            validation_data=[x_test, y_test])\n",
    "    return model\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting IMDB data with vocabulary_size 20000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<__array_function__ internals>:5: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\datasets\\imdb.py:159: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\datasets\\imdb.py:160: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "--- Test Case 1 ---\n",
      "Sentence: \"OOV OOV OOV OOV OOV OOV OOV OOV OOV OOV OOV OOV OOV OOV OOV OOV OOV OOV OOV OOV OOV OOV OOV OOV OOV OOV OOV OOV OOV OOV OOV OOV OOV please give this one a miss br br kristy swanson and the rest of the cast rendered terrible performances the show is flat flat flat br br i don't know how michael madison could have allowed this one on his plate he almost seemed to know this wasn't going to work out and his performance was quite lacklustre so all you madison fans give this a miss\"\n",
      "Truth: 0\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'predict'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-71-b8e1fe804ab7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m   \u001b[0mFLAGS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse_known_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m   \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-71-b8e1fe804ab7>\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     22\u001b[0m           ' '.join(indices_to_words(reverse_index, x_test[i, :])) + '\"')\n\u001b[0;32m     23\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Truth: %d'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Prediction: %s\\n'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m   \u001b[1;31m# Save metadata, including word index, INDEX_FROM and max_len and model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'predict'"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "  x_train, y_train, x_test, y_test = (\n",
    "      get_imdb_data(FLAGS.vocabulary_size, FLAGS.max_len))\n",
    "\n",
    "  model = train_model(FLAGS.model_type,\n",
    "                      FLAGS.vocabulary_size,\n",
    "                      FLAGS.embedding_size,\n",
    "                      x_train,\n",
    "                      y_train,\n",
    "                      x_test,\n",
    "                      y_test,\n",
    "                      FLAGS.epochs,\n",
    "                      FLAGS.batch_size)\n",
    "\n",
    "  # Display a number test phrases and their final classification.\n",
    "  forward_index = get_word_index()\n",
    "  reverse_index = get_word_index(reverse=True)\n",
    "  print('\\n')\n",
    "  for i in range(FLAGS.num_show):\n",
    "    print('--- Test Case %d ---' % (i + 1))\n",
    "    print('Sentence: \"' +\n",
    "          ' '.join(indices_to_words(reverse_index, x_test[i, :])) + '\"')\n",
    "    print('Truth: %d' % y_test[i])\n",
    "    print('Prediction: %s\\n' % model.predict(x_test[i : i + 1, :])[0][0])\n",
    "\n",
    "  # Save metadata, including word index, INDEX_FROM and max_len and model\n",
    "  # hyperparameters.\n",
    "  metadata = {\n",
    "      'word_index': forward_index,\n",
    "      'index_from': INDEX_FROM,\n",
    "      'max_len': FLAGS.max_len,\n",
    "      'model_type': FLAGS.model_type,\n",
    "      'vocabulary_size': FLAGS.vocabulary_size,\n",
    "      'embedding_size': FLAGS.embedding_size,\n",
    "      'epochs': FLAGS.epochs,\n",
    "      'batch_size': FLAGS.batch_size,\n",
    "  }\n",
    "\n",
    "if not os.path.isdir(FLAGS.artifacts_dir):\n",
    "    os.makedirs(FLAGS.artifacts_dir)\n",
    "    metadata_json_path = os.path.join(FLAGS.artifacts_dir, 'metadata.json')\n",
    "    json.dump(metadata, open(metadata_json_path, 'wt'))\n",
    "    print('\\nSaved model metadata at: %s' % metadata_json_path)\n",
    "\n",
    "    tfjs.converters.save_keras_model(model, FLAGS.artifacts_dir)\n",
    "    print('\\nSaved model artifacts in directory: %s' % FLAGS.artifacts_dir)\n",
    "\n",
    " \n",
    "if __name__ == '__main__':\n",
    "  parser = argparse.ArgumentParser('IMDB sentiment classification model')\n",
    "  parser.add_argument(\n",
    "      'model_type',\n",
    "      type=str,\n",
    "      help='Type of model to train for the IMDB sentiment classification task: '\n",
    "      '(cnn | lstm)')\n",
    "  parser.add_argument(\n",
    "      '--vocabulary_size',\n",
    "      type=int,\n",
    "      default=20000,\n",
    "      help='Vocabulary size.')\n",
    "  parser.add_argument(\n",
    "      '--embedding_size',\n",
    "      type=int,\n",
    "      default=128,\n",
    "      help='Embedding size.')\n",
    "  parser.add_argument(\n",
    "      '--max_len',\n",
    "      type=int,\n",
    "      default=100,\n",
    "      help='Cut text after this number of words.')\n",
    "  parser.add_argument(\n",
    "      '--epochs',\n",
    "      type=int,\n",
    "      default=5,\n",
    "      help='Number of epochs to train the model for.')\n",
    "  parser.add_argument(\n",
    "      '--batch_size',\n",
    "      type=int,\n",
    "      default=32,\n",
    "      help='Batch size used during training.')\n",
    "  parser.add_argument(\n",
    "      '--num_show',\n",
    "      type=int,\n",
    "      default=5,\n",
    "      help='Number of sentences to show prediction score on after training.')\n",
    "  parser.add_argument(\n",
    "      '--artifacts_dir',\n",
    "      type=str,\n",
    "      default='/tmp/imdb.keras',\n",
    "      help='Local path for saving the TensorFlow.js artifacts.')\n",
    "\n",
    "  FLAGS, _ = parser.parse_known_args()\n",
    "  main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
